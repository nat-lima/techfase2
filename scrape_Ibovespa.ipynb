{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "088be170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e7b381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "058ca76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://sistemaswebb3-listados.b3.com.br/indexPage/day/IBOV?language=pt-br'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c796dba4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=134.0.6998.117)\nStacktrace:\n\tGetHandleVerifier [0x0096B593+24387]\n\t(No symbol) [0x008F58F4]\n\t(No symbol) [0x007D0753]\n\t(No symbol) [0x007AF83E]\n\t(No symbol) [0x0084454E]\n\t(No symbol) [0x0085EA19]\n\t(No symbol) [0x0083D646]\n\t(No symbol) [0x0080C59F]\n\t(No symbol) [0x0080D8E4]\n\tGetHandleVerifier [0x00C6D873+3179043]\n\tGetHandleVerifier [0x00C86CE9+3282585]\n\tGetHandleVerifier [0x00C8166C+3260444]\n\tGetHandleVerifier [0x00A04320+650448]\n\t(No symbol) [0x008FECFD]\n\t(No symbol) [0x008FBAE8]\n\t(No symbol) [0x008FBC89]\n\t(No symbol) [0x008EE520]\n\tBaseThreadInitThunk [0x765B7BA9+25]\n\tRtlInitializeExceptionChain [0x77A2C0CB+107]\n\tRtlClearBits [0x77A2C04F+191]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNoSuchWindowException\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Wait for the container to be available\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m container = \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mEC\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpresence_of_element_located\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mID\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdivContainerIframeB3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFound the container:\u001b[39m\u001b[33m\"\u001b[39m, container)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MLET\\FaseII\\techfase2\\venv\\Lib\\site-packages\\selenium\\webdriver\\support\\wait.py:137\u001b[39m, in \u001b[36mWebDriverWait.until\u001b[39m\u001b[34m(self, method, message)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m         value = \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_driver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m value:\n\u001b[32m    139\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MLET\\FaseII\\techfase2\\venv\\Lib\\site-packages\\selenium\\webdriver\\support\\expected_conditions.py:110\u001b[39m, in \u001b[36mpresence_of_element_located.<locals>._predicate\u001b[39m\u001b[34m(driver)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_predicate\u001b[39m(driver: WebDriverOrWebElement):\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdriver\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlocator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MLET\\FaseII\\techfase2\\venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:898\u001b[39m, in \u001b[36mWebDriver.find_element\u001b[39m\u001b[34m(self, by, value)\u001b[39m\n\u001b[32m    895\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m NoSuchElementException(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot locate relative element with: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mby.root\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    896\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m elements[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m898\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43musing\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalue\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MLET\\FaseII\\techfase2\\venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:429\u001b[39m, in \u001b[36mWebDriver.execute\u001b[39m\u001b[34m(self, driver_command, params)\u001b[39m\n\u001b[32m    427\u001b[39m response = \u001b[38;5;28mself\u001b[39m.command_executor.execute(driver_command, params)\n\u001b[32m    428\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[32m--> \u001b[39m\u001b[32m429\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merror_handler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    430\u001b[39m     response[\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m._unwrap_value(response.get(\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    431\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MLET\\FaseII\\techfase2\\venv\\Lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:232\u001b[39m, in \u001b[36mErrorHandler.check_response\u001b[39m\u001b[34m(self, response)\u001b[39m\n\u001b[32m    230\u001b[39m         alert_text = value[\u001b[33m\"\u001b[39m\u001b[33malert\u001b[39m\u001b[33m\"\u001b[39m].get(\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    231\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[31mNoSuchWindowException\u001b[39m: Message: no such window: target window already closed\nfrom unknown error: web view not found\n  (Session info: chrome=134.0.6998.117)\nStacktrace:\n\tGetHandleVerifier [0x0096B593+24387]\n\t(No symbol) [0x008F58F4]\n\t(No symbol) [0x007D0753]\n\t(No symbol) [0x007AF83E]\n\t(No symbol) [0x0084454E]\n\t(No symbol) [0x0085EA19]\n\t(No symbol) [0x0083D646]\n\t(No symbol) [0x0080C59F]\n\t(No symbol) [0x0080D8E4]\n\tGetHandleVerifier [0x00C6D873+3179043]\n\tGetHandleVerifier [0x00C86CE9+3282585]\n\tGetHandleVerifier [0x00C8166C+3260444]\n\tGetHandleVerifier [0x00A04320+650448]\n\t(No symbol) [0x008FECFD]\n\t(No symbol) [0x008FBAE8]\n\t(No symbol) [0x008FBC89]\n\t(No symbol) [0x008EE520]\n\tBaseThreadInitThunk [0x765B7BA9+25]\n\tRtlInitializeExceptionChain [0x77A2C0CB+107]\n\tRtlClearBits [0x77A2C04F+191]\n"
     ]
    }
   ],
   "source": [
    "# Wait for the container to be available\n",
    "container = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.ID, \"divContainerIframeB3\"))\n",
    ")\n",
    "print(\"Found the container:\", container)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e6d4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-19\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Extract the date from the container\n",
    "date_element = container.find_element(By.XPATH, \"//p[contains(text(), 'Carteira Teórica do IBovespa válida para')]\")\n",
    "date_text = date_element.text.split(\"para\")[-1].strip()  # Extracts '17/03/25'\n",
    "\n",
    "# Convert the date to ISO 8601 format (YYYY-MM-DD)\n",
    "parsed_date = datetime.strptime(date_text, \"%d/%m/%y\")  # Parse the date using the original format\n",
    "formatted_date = parsed_date.strftime(\"%Y-%m-%d\")  # Format it to ISO 8601\n",
    "\n",
    "# Now formatted_date contains the string in 'YYYY-MM-DD' format\n",
    "print(formatted_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a54201c",
   "metadata": {},
   "source": [
    "*** SCRAPE ONE PAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c3f384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame with date column saved as ibovespa_2025-03-19.parquet\n"
     ]
    }
   ],
   "source": [
    "# Locate the table within the container\n",
    "table = container.find_element(By.TAG_NAME, \"table\")\n",
    "rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "# Extract header\n",
    "headers = [header.text for header in rows[0].find_elements(By.TAG_NAME, \"th\")]\n",
    "\n",
    "# Extract rows\n",
    "data = []\n",
    "for row in rows[1:]:\n",
    "    cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "    data.append([col.text for col in cols])\n",
    "\n",
    "# Convert to Pandas DataFrame\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "\n",
    "# Add the extracted date to the DataFrame as a new column\n",
    "df[\"Date\"] = formatted_date\n",
    "\n",
    "# Save the DataFrame to a Parquet file with the date in the name\n",
    "parquet_file_name = f\"ibovespa_{formatted_date}.parquet\"\n",
    "df.to_parquet(f'data\\\\{parquet_file_name}', engine=\"pyarrow\", index=False)\n",
    "\n",
    "csv_file_name = parquet_file_name.replace(\".parquet\", \".csv\")  # Replace the extension\n",
    "df.to_csv(f'data\\\\{csv_file_name}', index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"DataFrame with date column saved as {parquet_file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef82fe9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Código",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Ação",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Tipo",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Qtde. Teórica",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Part. (%)",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Date",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8cf49847-142a-499d-9a50-5ba7c435b9cd",
       "rows": [
        [
         "0",
         "ALOS3",
         "ALLOS",
         "ON NM",
         "476.976.044",
         "0,442",
         "2025-03-19"
        ],
        [
         "1",
         "ABEV3",
         "AMBEV S/A",
         "ON ED",
         "4.394.835.131",
         "2,820",
         "2025-03-19"
        ],
        [
         "2",
         "ASAI3",
         "ASSAI",
         "ON NM",
         "1.345.832.968",
         "0,481",
         "2025-03-19"
        ],
        [
         "3",
         "AURE3",
         "AUREN",
         "ON NM",
         "323.738.747",
         "0,120",
         "2025-03-19"
        ],
        [
         "4",
         "AMOB3",
         "AUTOMOB",
         "ON NM",
         "533.959.816",
         "0,007",
         "2025-03-19"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Código</th>\n",
       "      <th>Ação</th>\n",
       "      <th>Tipo</th>\n",
       "      <th>Qtde. Teórica</th>\n",
       "      <th>Part. (%)</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALOS3</td>\n",
       "      <td>ALLOS</td>\n",
       "      <td>ON NM</td>\n",
       "      <td>476.976.044</td>\n",
       "      <td>0,442</td>\n",
       "      <td>2025-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABEV3</td>\n",
       "      <td>AMBEV S/A</td>\n",
       "      <td>ON ED</td>\n",
       "      <td>4.394.835.131</td>\n",
       "      <td>2,820</td>\n",
       "      <td>2025-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASAI3</td>\n",
       "      <td>ASSAI</td>\n",
       "      <td>ON NM</td>\n",
       "      <td>1.345.832.968</td>\n",
       "      <td>0,481</td>\n",
       "      <td>2025-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AURE3</td>\n",
       "      <td>AUREN</td>\n",
       "      <td>ON NM</td>\n",
       "      <td>323.738.747</td>\n",
       "      <td>0,120</td>\n",
       "      <td>2025-03-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMOB3</td>\n",
       "      <td>AUTOMOB</td>\n",
       "      <td>ON NM</td>\n",
       "      <td>533.959.816</td>\n",
       "      <td>0,007</td>\n",
       "      <td>2025-03-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Código       Ação   Tipo  Qtde. Teórica Part. (%)        Date\n",
       "0  ALOS3      ALLOS  ON NM    476.976.044     0,442  2025-03-19\n",
       "1  ABEV3  AMBEV S/A  ON ED  4.394.835.131     2,820  2025-03-19\n",
       "2  ASAI3      ASSAI  ON NM  1.345.832.968     0,481  2025-03-19\n",
       "3  AURE3      AUREN  ON NM    323.738.747     0,120  2025-03-19\n",
       "4  AMOB3    AUTOMOB  ON NM    533.959.816     0,007  2025-03-19"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4a910a",
   "metadata": {},
   "source": [
    "### TRYING TO SCRAPE ALL PAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797c778d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pages to scrape: 5\n"
     ]
    }
   ],
   "source": [
    "# Function to get the total number of pages\n",
    "def get_total_pages(driver):\n",
    "    pagination_element = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, \"//ul[@class='ngx-pagination']\"))\n",
    "    )\n",
    "    pages = pagination_element.find_elements(By.TAG_NAME, \"li\")\n",
    "    last_page_text = pages[-2].text.strip()\n",
    "    total_pages = int(''.join(filter(str.isdigit, last_page_text)))  # Clean and convert\n",
    "    return total_pages\n",
    "\n",
    "# Initialize an empty list to store data from all pages\n",
    "all_data = []\n",
    "\n",
    "# Get the total number of pages\n",
    "total_pages = get_total_pages(driver)\n",
    "print(f\"Total pages to scrape: {total_pages}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2176a9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1...\n",
      "scrapping ABEV3\n",
      "scrapping AMBEV S/A\n",
      "scrapping ON ED\n",
      "scrapping 4.394.835.131\n",
      "scrapping 2,820\n",
      "scrapping ASAI3\n",
      "scrapping ASSAI\n",
      "scrapping ON NM\n",
      "scrapping 1.345.832.968\n",
      "scrapping 0,481\n",
      "scrapping AURE3\n",
      "scrapping AUREN\n",
      "scrapping ON NM\n",
      "scrapping 323.738.747\n",
      "scrapping 0,120\n",
      "scrapping AMOB3\n",
      "scrapping AUTOMOB\n",
      "scrapping ON NM\n",
      "scrapping 533.959.816\n",
      "scrapping 0,007\n",
      "scrapping AZUL4\n",
      "scrapping AZUL\n",
      "scrapping PN N2\n",
      "scrapping 326.872.005\n",
      "scrapping 0,058\n",
      "scrapping AZZA3\n",
      "scrapping AZZAS 2154\n",
      "scrapping ON NM\n",
      "scrapping 136.643.320\n",
      "scrapping 0,149\n",
      "scrapping B3SA3\n",
      "scrapping B3\n",
      "scrapping ON NM\n",
      "scrapping 5.392.540.963\n",
      "scrapping 3,075\n",
      "scrapping BBSE3\n",
      "scrapping BBSEGURIDADE\n",
      "scrapping ON NM\n",
      "scrapping 637.332.335\n",
      "scrapping 1,219\n",
      "scrapping BBDC3\n",
      "scrapping BRADESCO\n",
      "scrapping ON N1\n",
      "scrapping 1.484.426.957\n",
      "scrapping 0,789\n",
      "scrapping BBDC4\n",
      "scrapping BRADESCO\n",
      "scrapping PN N1\n",
      "scrapping 5.129.958.973\n",
      "scrapping 2,988\n",
      "scrapping BRAP4\n",
      "scrapping BRADESPAR\n",
      "scrapping PN N1\n",
      "scrapping 250.969.312\n",
      "scrapping 0,212\n",
      "scrapping BBAS3\n",
      "scrapping BRASIL\n",
      "scrapping ON EX NM\n",
      "scrapping 2.842.613.858\n",
      "scrapping 3,836\n",
      "scrapping BRKM5\n",
      "scrapping BRASKEM\n",
      "scrapping PNA N1\n",
      "scrapping 265.388.400\n",
      "scrapping 0,141\n",
      "scrapping BRAV3\n",
      "scrapping BRAVA\n",
      "scrapping ON NM\n",
      "scrapping 460.791.208\n",
      "scrapping 0,402\n",
      "scrapping BRFS3\n",
      "scrapping BRF SA\n",
      "scrapping ON NM\n",
      "scrapping 814.523.002\n",
      "scrapping 0,758\n",
      "scrapping BPAC11\n",
      "scrapping BTGP BANCO\n",
      "scrapping UNT N2\n",
      "scrapping 1.287.247.964\n",
      "scrapping 2,168\n",
      "scrapping CXSE3\n",
      "scrapping CAIXA SEGURI\n",
      "scrapping ON NM\n",
      "scrapping 517.500.000\n",
      "scrapping 0,384\n",
      "scrapping CRFB3\n",
      "scrapping CARREFOUR BR\n",
      "scrapping ON NM\n",
      "scrapping 532.664.283\n",
      "scrapping 0,187\n",
      "scrapping CCRO3\n",
      "scrapping CCR SA\n",
      "scrapping ON NM\n",
      "scrapping 991.920.937\n",
      "scrapping 0,563\n",
      "Scraping page 2...\n",
      "scrapping COGN3\n",
      "scrapping COGNA ON\n",
      "scrapping ON NM\n",
      "scrapping 1.872.454.628\n",
      "scrapping 0,162\n",
      "scrapping CPLE6\n",
      "scrapping COPEL\n",
      "scrapping PNB N2\n",
      "scrapping 1.679.233.590\n",
      "scrapping 0,828\n",
      "scrapping CSAN3\n",
      "scrapping COSAN\n",
      "scrapping ON NM\n",
      "scrapping 1.150.987.430\n",
      "scrapping 0,419\n",
      "scrapping CPFE3\n",
      "scrapping CPFL ENERGIA\n",
      "scrapping ON NM\n",
      "scrapping 187.732.538\n",
      "scrapping 0,338\n",
      "scrapping CMIN3\n",
      "scrapping CSNMINERACAO\n",
      "scrapping ON N2\n",
      "scrapping 1.646.519.336\n",
      "scrapping 0,487\n",
      "scrapping CVCB3\n",
      "scrapping CVC BRASIL\n",
      "scrapping ON NM\n",
      "scrapping 525.591.097\n",
      "scrapping 0,049\n",
      "scrapping CYRE3\n",
      "scrapping CYRELA REALT\n",
      "scrapping ON NM\n",
      "scrapping 273.755.006\n",
      "scrapping 0,304\n",
      "scrapping ELET3\n",
      "scrapping ELETROBRAS\n",
      "scrapping ON N1\n",
      "scrapping 1.977.170.723\n",
      "scrapping 3,807\n",
      "scrapping ELET6\n",
      "scrapping ELETROBRAS\n",
      "scrapping PNB N1\n",
      "scrapping 268.875.696\n",
      "scrapping 0,564\n",
      "scrapping EMBR3\n",
      "scrapping EMBRAER\n",
      "scrapping ON NM\n",
      "scrapping 734.631.801\n",
      "scrapping 2,714\n",
      "scrapping ENGI11\n",
      "scrapping ENERGISA\n",
      "scrapping UNT N2\n",
      "scrapping 326.175.300\n",
      "scrapping 0,642\n",
      "scrapping ENEV3\n",
      "scrapping ENEVA\n",
      "scrapping ON NM\n",
      "scrapping 1.929.556.616\n",
      "scrapping 1,150\n",
      "scrapping EGIE3\n",
      "scrapping ENGIE BRASIL\n",
      "scrapping ON NM\n",
      "scrapping 255.236.938\n",
      "scrapping 0,467\n",
      "scrapping EQTL3\n",
      "scrapping EQUATORIAL\n",
      "scrapping ON NM\n",
      "scrapping 1.253.541.010\n",
      "scrapping 1,936\n",
      "scrapping FLRY3\n",
      "scrapping FLEURY\n",
      "scrapping ON NM\n",
      "scrapping 455.988.366\n",
      "scrapping 0,251\n",
      "scrapping GGBR4\n",
      "scrapping GERDAU\n",
      "scrapping PN N1\n",
      "scrapping 1.242.683.687\n",
      "scrapping 1,013\n",
      "scrapping GOAU4\n",
      "scrapping GERDAU MET\n",
      "scrapping PN N1\n",
      "scrapping 649.238.303\n",
      "scrapping 0,291\n",
      "scrapping NTCO3\n",
      "scrapping GRUPO NATURA\n",
      "scrapping ON NM\n",
      "scrapping 850.935.197\n",
      "scrapping 0,383\n",
      "scrapping HAPV3\n",
      "scrapping HAPVIDA\n",
      "scrapping ON NM\n",
      "scrapping 4.779.395.040\n",
      "scrapping 0,534\n",
      "Scraping page 3...\n",
      "scrapping IGTI11\n",
      "scrapping IGUATEMI S.A\n",
      "scrapping UNT N1\n",
      "scrapping 211.783.588\n",
      "scrapping 0,190\n",
      "scrapping IRBR3\n",
      "scrapping IRBBRASIL RE\n",
      "scrapping ON NM\n",
      "scrapping 81.838.243\n",
      "scrapping 0,187\n",
      "scrapping ISAE4\n",
      "scrapping ISA ENERGIA\n",
      "scrapping PN EJ N1\n",
      "scrapping 395.801.044\n",
      "scrapping 0,431\n",
      "scrapping ITSA4\n",
      "scrapping ITAUSA\n",
      "scrapping PN N1\n",
      "scrapping 5.857.796.242\n",
      "scrapping 2,657\n",
      "scrapping ITUB4\n",
      "scrapping ITAUUNIBANCO\n",
      "scrapping PN EB N1\n",
      "scrapping 5.272.192.664\n",
      "scrapping 8,064\n",
      "scrapping JBSS3\n",
      "scrapping JBS\n",
      "scrapping ON NM\n",
      "scrapping 1.145.962.972\n",
      "scrapping 2,095\n",
      "scrapping KLBN11\n",
      "scrapping KLABIN S/A\n",
      "scrapping UNT N2\n",
      "scrapping 765.785.673\n",
      "scrapping 0,721\n",
      "scrapping RENT3\n",
      "scrapping LOCALIZA\n",
      "scrapping ON NM\n",
      "scrapping 965.986.531\n",
      "scrapping 1,505\n",
      "scrapping LREN3\n",
      "scrapping LOJAS RENNER\n",
      "scrapping ON NM\n",
      "scrapping 1.051.120.777\n",
      "scrapping 0,614\n",
      "scrapping LWSA3\n",
      "scrapping LWSA\n",
      "scrapping ON NM\n",
      "scrapping 389.635.155\n",
      "scrapping 0,048\n",
      "scrapping MGLU3\n",
      "scrapping MAGAZ LUIZA\n",
      "scrapping ON NM\n",
      "scrapping 353.448.195\n",
      "scrapping 0,168\n",
      "scrapping POMO4\n",
      "scrapping MARCOPOLO\n",
      "scrapping PN N2\n",
      "scrapping 666.378.439\n",
      "scrapping 0,216\n",
      "scrapping MRFG3\n",
      "scrapping MARFRIG\n",
      "scrapping ON NM\n",
      "scrapping 302.019.876\n",
      "scrapping 0,226\n",
      "scrapping BEEF3\n",
      "scrapping MINERVA\n",
      "scrapping ON NM\n",
      "scrapping 261.359.935\n",
      "scrapping 0,068\n",
      "scrapping MRVE3\n",
      "scrapping MRV\n",
      "scrapping ON NM\n",
      "scrapping 377.241.484\n",
      "scrapping 0,092\n",
      "scrapping MULT3\n",
      "scrapping MULTIPLAN\n",
      "scrapping ON N2\n",
      "scrapping 314.150.156\n",
      "scrapping 0,346\n",
      "scrapping PCAR3\n",
      "scrapping P.ACUCAR-CBD\n",
      "scrapping ON NM\n",
      "scrapping 462.534.972\n",
      "scrapping 0,055\n",
      "scrapping PETR3\n",
      "scrapping PETROBRAS\n",
      "scrapping ON N2\n",
      "scrapping 2.255.782.178\n",
      "scrapping 4,201\n",
      "scrapping PETR4\n",
      "scrapping PETROBRAS\n",
      "scrapping PN ATZ N2\n",
      "scrapping 4.431.132.660\n",
      "scrapping 7,594\n",
      "Scraping page 4...\n",
      "scrapping PRIO3\n",
      "scrapping PETRORIO\n",
      "scrapping ON NM\n",
      "scrapping 779.999.989\n",
      "scrapping 1,465\n",
      "scrapping PETZ3\n",
      "scrapping PETZ\n",
      "scrapping ON NM\n",
      "scrapping 293.689.428\n",
      "scrapping 0,064\n",
      "scrapping PSSA3\n",
      "scrapping PORTO SEGURO\n",
      "scrapping ON NM\n",
      "scrapping 182.560.698\n",
      "scrapping 0,349\n",
      "scrapping RADL3\n",
      "scrapping RAIADROGASIL\n",
      "scrapping ON NM\n",
      "scrapping 1.286.616.979\n",
      "scrapping 1,197\n",
      "scrapping RAIZ4\n",
      "scrapping RAIZEN\n",
      "scrapping PN N2\n",
      "scrapping 1.198.936.529\n",
      "scrapping 0,104\n",
      "scrapping RDOR3\n",
      "scrapping REDE D OR\n",
      "scrapping ON NM\n",
      "scrapping 1.145.289.019\n",
      "scrapping 1,554\n",
      "scrapping RAIL3\n",
      "scrapping RUMO S.A.\n",
      "scrapping ON NM\n",
      "scrapping 1.216.914.397\n",
      "scrapping 1,040\n",
      "scrapping SBSP3\n",
      "scrapping SABESP\n",
      "scrapping ON NM\n",
      "scrapping 683.508.568\n",
      "scrapping 3,246\n",
      "scrapping SANB11\n",
      "scrapping SANTANDER BR\n",
      "scrapping UNT\n",
      "scrapping 356.586.730\n",
      "scrapping 0,451\n",
      "scrapping STBP3\n",
      "scrapping SANTOS BRP\n",
      "scrapping ON NM\n",
      "scrapping 855.712.622\n",
      "scrapping 0,541\n",
      "scrapping SMTO3\n",
      "scrapping SAO MARTINHO\n",
      "scrapping ON NM\n",
      "scrapping 128.130.966\n",
      "scrapping 0,137\n",
      "scrapping CSNA3\n",
      "scrapping SID NACIONAL\n",
      "scrapping ON\n",
      "scrapping 727.459.637\n",
      "scrapping 0,339\n",
      "scrapping SLCE3\n",
      "scrapping SLC AGRICOLA\n",
      "scrapping ON NM\n",
      "scrapping 194.261.422\n",
      "scrapping 0,178\n",
      "scrapping SUZB3\n",
      "scrapping SUZANO S.A.\n",
      "scrapping ON NM\n",
      "scrapping 630.821.784\n",
      "scrapping 1,643\n",
      "scrapping TAEE11\n",
      "scrapping TAESA\n",
      "scrapping UNT N2\n",
      "scrapping 218.568.234\n",
      "scrapping 0,356\n",
      "scrapping VIVT3\n",
      "scrapping TELEF BRASIL\n",
      "scrapping ON\n",
      "scrapping 382.442.128\n",
      "scrapping 0,929\n",
      "scrapping TIMS3\n",
      "scrapping TIM\n",
      "scrapping ON NM\n",
      "scrapping 807.495.418\n",
      "scrapping 0,660\n",
      "scrapping TOTS3\n",
      "scrapping TOTVS\n",
      "scrapping ON NM\n",
      "scrapping 540.206.440\n",
      "scrapping 0,887\n",
      "scrapping UGPA3\n",
      "scrapping ULTRAPAR\n",
      "scrapping ON NM\n",
      "scrapping 1.090.134.379\n",
      "scrapping 0,889\n",
      "Scraping page 5...\n",
      "scrapping VALE3\n",
      "scrapping VALE\n",
      "scrapping ON ED NM\n",
      "scrapping 4.270.903.023\n",
      "scrapping 11,634\n",
      "scrapping VAMO3\n",
      "scrapping VAMOS\n",
      "scrapping ON NM\n",
      "scrapping 485.166.826\n",
      "scrapping 0,094\n",
      "scrapping VBBR3\n",
      "scrapping VIBRA\n",
      "scrapping ON NM\n",
      "scrapping 1.023.538.460\n",
      "scrapping 0,847\n",
      "scrapping VIVA3\n",
      "scrapping VIVARA S.A.\n",
      "scrapping ON NM\n",
      "scrapping 125.446.075\n",
      "scrapping 0,106\n",
      "scrapping WEGE3\n",
      "scrapping WEG\n",
      "scrapping ON NM\n",
      "scrapping 1.243.177.587\n",
      "scrapping 2,805\n",
      "scrapping YDUQ3\n",
      "scrapping YDUQS PART\n",
      "scrapping ON ATZ NM\n",
      "scrapping 277.677.050\n",
      "scrapping 0,157\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "5 columns passed, passed data had 13 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MLET\\FaseII\\techfase2\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:939\u001b[39m, in \u001b[36m_finalize_columns_and_data\u001b[39m\u001b[34m(content, columns, dtype)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m939\u001b[39m     columns = \u001b[43m_validate_or_indexify_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    941\u001b[39m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MLET\\FaseII\\techfase2\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:986\u001b[39m, in \u001b[36m_validate_or_indexify_columns\u001b[39m\u001b[34m(content, columns)\u001b[39m\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_mi_list \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(columns) != \u001b[38;5;28mlen\u001b[39m(content):  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[32m    985\u001b[39m     \u001b[38;5;66;03m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m986\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[32m    987\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(columns)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m columns passed, passed data had \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    988\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(content)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m columns\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    989\u001b[39m     )\n\u001b[32m    990\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_mi_list:\n\u001b[32m    991\u001b[39m     \u001b[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: 5 columns passed, passed data had 13 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     48\u001b[39m         time.sleep(\u001b[32m10\u001b[39m);\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Attach footer content to the all_data array\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m#for rowf in rowfooter:\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m#    colsf = rowf.find_elements(By.TAG_NAME, \"td\")\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m#    all_data.append([col.text for col in colsf])\u001b[39;00m\n\u001b[32m     54\u001b[39m \n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Convert collected data to a Pandas DataFrame\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Add the extracted date to the DataFrame\u001b[39;00m\n\u001b[32m     59\u001b[39m df[\u001b[33m\"\u001b[39m\u001b[33mData\u001b[39m\u001b[33m\"\u001b[39m] = formatted_date\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MLET\\FaseII\\techfase2\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:851\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    849\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    850\u001b[39m         columns = ensure_index(columns)\n\u001b[32m--> \u001b[39m\u001b[32m851\u001b[39m     arrays, columns, index = \u001b[43mnested_data_to_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[32m    853\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[32m    854\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    857\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    859\u001b[39m     mgr = arrays_to_mgr(\n\u001b[32m    860\u001b[39m         arrays,\n\u001b[32m    861\u001b[39m         columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    864\u001b[39m         typ=manager,\n\u001b[32m    865\u001b[39m     )\n\u001b[32m    866\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MLET\\FaseII\\techfase2\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:520\u001b[39m, in \u001b[36mnested_data_to_arrays\u001b[39m\u001b[34m(data, columns, index, dtype)\u001b[39m\n\u001b[32m    517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_named_tuple(data[\u001b[32m0\u001b[39m]) \u001b[38;5;129;01mand\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    518\u001b[39m     columns = ensure_index(data[\u001b[32m0\u001b[39m]._fields)\n\u001b[32m--> \u001b[39m\u001b[32m520\u001b[39m arrays, columns = \u001b[43mto_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    521\u001b[39m columns = ensure_index(columns)\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MLET\\FaseII\\techfase2\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:845\u001b[39m, in \u001b[36mto_arrays\u001b[39m\u001b[34m(data, columns, dtype)\u001b[39m\n\u001b[32m    842\u001b[39m     data = [\u001b[38;5;28mtuple\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[32m    843\u001b[39m     arr = _list_to_arrays(data)\n\u001b[32m--> \u001b[39m\u001b[32m845\u001b[39m content, columns = \u001b[43m_finalize_columns_and_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m content, columns\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\MLET\\FaseII\\techfase2\\venv\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:942\u001b[39m, in \u001b[36m_finalize_columns_and_data\u001b[39m\u001b[34m(content, columns, dtype)\u001b[39m\n\u001b[32m    939\u001b[39m     columns = _validate_or_indexify_columns(contents, columns)\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    941\u001b[39m     \u001b[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    944\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(contents) \u001b[38;5;129;01mand\u001b[39;00m contents[\u001b[32m0\u001b[39m].dtype == np.object_:\n\u001b[32m    945\u001b[39m     contents = convert_object_array(contents, dtype=dtype)\n",
      "\u001b[31mValueError\u001b[39m: 5 columns passed, passed data had 13 columns"
     ]
    }
   ],
   "source": [
    "# Loop through all pages\n",
    "page = 0\n",
    "for page_number in range(1, total_pages + 1):\n",
    "    page = page_number\n",
    "    print(f\"Scraping page {page_number}...\")\n",
    "\n",
    "    # Locate the table on the current page\n",
    "    table = container.find_element(By.TAG_NAME, \"table\")\n",
    "    thead = table.find_element(By.TAG_NAME, \"thead\")\n",
    "    tbody = table.find_element(By.TAG_NAME, \"tbody\")\n",
    "    tfoot = table.find_element(By.TAG_NAME, \"tfoot\")\n",
    "    \n",
    "    #locate rows inside TBody\n",
    "    rows = tbody.find_elements(By.TAG_NAME, \"tr\")\n",
    "    \n",
    "    # Extract headers (only on the first iteration) and prepare the code to get footer content\n",
    "    if page_number == 1:\n",
    "        rowheader = thead.find_elements(By.TAG_NAME, \"tr\")\n",
    "        #headers = [header.text.replace(\"Qtde. Teórica\",\"Qtde\").replace(\"Part. (%)\",\"Part\").replace(\"Código\",\"Codigo\").replace(\"Ação\",\"Acao\")  \n",
    "        #           for header in rowheader[0].find_elements(By.TAG_NAME, \"th\")]\n",
    "        headers = [header.text for header in rowheader[0].find_elements(By.TAG_NAME, \"th\")]        \n",
    "        rowfooter = tfoot.find_elements(By.TAG_NAME, \"tr\")\n",
    "\n",
    "    # Extract row data\n",
    "    for row in rows[1:]:\n",
    "        cols = row.find_elements(By.TAG_NAME, \"td\")\n",
    "        all_data.append([cols[0].text, cols[1].text, cols[2].text, int(cols[3].text.replace(\".\", \"\")), float(cols[4].text.replace(\",\", \".\"))])\n",
    "        \n",
    "        #all_data.append(\n",
    "        #                    [\n",
    "        #                        float(col.text.replace(\".\", \"\")) if col.text.replace(\".\", \"\").isdigit() else(float(col.text.replace(\",\",\".\")) if col.text.replace(\",\",\".\").isdigit() else col.text)  for col in cols\n",
    "        #                    ]\n",
    "        #                )\n",
    "       \n",
    "        #i = 0;\n",
    "        #colcontent = int(col.text.replace(\".\",\"\")) if i == 4  else (float(col.text.replace(\",\",\".\")) if i == 5 else col.text) \n",
    "        #all_data.append(colcontent)       \n",
    "    \n",
    "    # Go to the next page if not on the last one\n",
    "    if page_number < total_pages:\n",
    "        element = driver.find_element(By.XPATH, \"//li[contains(@class, 'pagination-next')]/a\")\n",
    "        element.click();\n",
    "        time.sleep(10);\n",
    "\n",
    "# Attach footer content to the all_data array\n",
    "#for rowf in rowfooter:\n",
    "#    colsf = rowf.find_elements(By.TAG_NAME, \"td\")\n",
    "#    all_data.append([col.text for col in colsf])\n",
    "\n",
    "# Convert collected data to a Pandas DataFrame\n",
    "df = pd.DataFrame(all_data, columns=headers)\n",
    "\n",
    "# Add the extracted date to the DataFrame\n",
    "df[\"Data\"] = formatted_date\n",
    "\n",
    "# Save the DataFrame to a Parquet file and a CSV file\n",
    "parquet_file_name = f\"data\\\\ibovespa_{formatted_date}.parquet\"\n",
    "df.to_parquet(parquet_file_name, engine=\"pyarrow\", index=False)\n",
    "\n",
    "csv_file_name = parquet_file_name.replace(\".parquet\", \".csv\")\n",
    "df.to_csv(csv_file_name, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Data saved: Parquet: {parquet_file_name}, CSV: {csv_file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0611d287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
